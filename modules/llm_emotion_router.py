"""
ğŸ§  LLM èªæ°£åˆ¤æ–·å™¨ï¼ˆGPT è‡ªå‹•æ¨™èªæ°£ï¼‰

ä½¿ç”¨ GPT/Claude ç­‰ LLM æ ¹æ“šè¼¸å…¥æ–‡å­—èªæ„ï¼Œè‡ªå‹•åŠ ä¸Šé©åˆçš„ ElevenLabs v3 èªæ°£æ¨™ç±¤ã€‚
"""

import os
from typing import Optional
from dotenv import load_dotenv

load_dotenv()

# æ”¯æ´å¤šç¨® LLM Provider
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
OPENAI_MODEL = os.getenv("OPENAI_MODEL", "gpt-4o-mini")  # é è¨­ä½¿ç”¨ gpt-4o-mini
ANTHROPIC_API_KEY = os.getenv("ANTHROPIC_API_KEY")


# ElevenLabs v3 æ”¯æ´çš„èªæ°£æ¨™ç±¤
AVAILABLE_EMOTION_TAGS = [
    "excited",          # èˆˆå¥®
    "whispers",         # æ‚„æ‚„è©±
    "sarcastic",        # è«·åˆº
    "curious",          # å¥½å¥‡
    "softly",           # è¼•æŸ”
    "crying",           # å“­æ³£
    "starts laughing",  # é–‹å§‹ç¬‘
    "sings",            # å”±æ­Œ
    "angry",            # ç”Ÿæ°£
    "playful",          # èª¿çš®
    "speaks quickly",  # å¿«é€Ÿèªªè©±
    "sighs",            # å˜†æ¯
    "happy",            # é–‹å¿ƒ
    "sad",              # é›£é
    "surprised",        # é©šè¨
    "whispering",       # ä½èª
    "echoes",           # å›éŸ³
]


def create_emotion_prompt(text: str) -> str:
    """
    å»ºç«‹èªæ°£åˆ¤æ–·çš„ Prompt
    
    Args:
        text: è¼¸å…¥æ–‡å­—
        
    Returns:
        Prompt å­—ä¸²
    """
    prompt = f"""è«‹æ ¹æ“šè¼¸å…¥çš„å¥å­åˆ¤æ–·èªæ°£ï¼Œä¸¦æ’å…¥æœ€åˆé©çš„ ElevenLabs æ¨™ç±¤ã€‚

å¯ç”¨çš„æ¨™ç±¤åŒ…æ‹¬ï¼š{', '.join([f'[{tag}]' for tag in AVAILABLE_EMOTION_TAGS])}

è¦å‰‡ï¼š
1. æ ¹æ“šèªæ„å’Œæƒ…æ„Ÿé¸æ“‡æœ€é©åˆçš„æ¨™ç±¤ï¼ˆå¯å¤šå€‹ï¼‰
2. æ¨™ç±¤æ ¼å¼ï¼š[tag1][tag2] æ–‡å­—å…§å®¹
3. å¦‚æœä¸éœ€è¦ç‰¹æ®Šèªæ°£ï¼Œç›´æ¥è¿”å›åŸæ–‡å­—

ç¯„ä¾‹ï¼š
è¼¸å…¥ï¼šä½ çŸ¥é“å—ï¼Ÿæˆ‘çœŸçš„å¥½æ„Ÿå‹•ã€‚
è¼¸å‡ºï¼š[crying][softly] ä½ çŸ¥é“å—ï¼Ÿæˆ‘çœŸçš„å¥½æ„Ÿå‹•ã€‚

è¼¸å…¥ï¼šå¤ªå¥½äº†ï¼æˆ‘å€‘æˆåŠŸäº†ï¼
è¼¸å‡ºï¼š[excited][happy] å¤ªå¥½äº†ï¼æˆ‘å€‘æˆåŠŸäº†ï¼

è¼¸å…¥ï¼šé€™æ˜¯å€‹ç§˜å¯†ï¼Œä¸è¦å‘Šè¨´åˆ¥äººã€‚
è¼¸å‡ºï¼š[whispers] é€™æ˜¯å€‹ç§˜å¯†ï¼Œä¸è¦å‘Šè¨´åˆ¥äººã€‚

ç¾åœ¨è«‹è™•ç†ä»¥ä¸‹è¼¸å…¥ï¼š
è¼¸å…¥ï¼š{text}
è¼¸å‡ºï¼š"""
    
    return prompt


def llm_emotion_route_openai(text: str, model: str = "gpt-4o-mini") -> Optional[str]:
    """
    ä½¿ç”¨ OpenAI API åˆ¤æ–·èªæ°£
    
    Args:
        text: è¼¸å…¥æ–‡å­—
        model: ä½¿ç”¨çš„æ¨¡å‹ï¼ˆé è¨­ gpt-4o-miniï¼‰
        
    Returns:
        åŠ ä¸Šèªæ°£æ¨™ç±¤çš„æ–‡å­—ï¼Œå¤±æ•—è¿”å› None
    """
    try:
        import openai
        
        if not OPENAI_API_KEY:
            print("âš ï¸  æœªè¨­å®š OPENAI_API_KEYï¼Œä½¿ç”¨è¦å‰‡å¼åˆ¤æ–·")
            return None
        
        client = openai.OpenAI(api_key=OPENAI_API_KEY)
        
        prompt = create_emotion_prompt(text)
        
        response = client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€å€‹èªæ°£åˆ¤æ–·å°ˆå®¶ï¼Œå°ˆé–€ç‚ºæ–‡å­—æ·»åŠ  ElevenLabs èªæ°£æ¨™ç±¤ã€‚"},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7,
            max_tokens=200
        )
        
        result = response.choices[0].message.content.strip()
        return result
        
    except ImportError:
        print("âš ï¸  æœªå®‰è£ openai å¥—ä»¶ï¼Œè«‹åŸ·è¡Œï¼špip install openai")
        return None
    except Exception as e:
        print(f"âŒ OpenAI API éŒ¯èª¤ï¼š{str(e)}")
        return None


def llm_emotion_route_anthropic(text: str, model: str = "claude-3-haiku-20240307") -> Optional[str]:
    """
    ä½¿ç”¨ Anthropic Claude API åˆ¤æ–·èªæ°£
    
    Args:
        text: è¼¸å…¥æ–‡å­—
        model: ä½¿ç”¨çš„æ¨¡å‹
        
    Returns:
        åŠ ä¸Šèªæ°£æ¨™ç±¤çš„æ–‡å­—ï¼Œå¤±æ•—è¿”å› None
    """
    try:
        import anthropic
        
        if not ANTHROPIC_API_KEY:
            print("âš ï¸  æœªè¨­å®š ANTHROPIC_API_KEYï¼Œä½¿ç”¨è¦å‰‡å¼åˆ¤æ–·")
            return None
        
        client = anthropic.Anthropic(api_key=ANTHROPIC_API_KEY)
        
        prompt = create_emotion_prompt(text)
        
        message = client.messages.create(
            model=model,
            max_tokens=200,
            messages=[
                {"role": "user", "content": prompt}
            ]
        )
        
        result = message.content[0].text.strip()
        return result
        
    except ImportError:
        print("âš ï¸  æœªå®‰è£ anthropic å¥—ä»¶ï¼Œè«‹åŸ·è¡Œï¼špip install anthropic")
        return None
    except Exception as e:
        print(f"âŒ Anthropic API éŒ¯èª¤ï¼š{str(e)}")
        return None


def llm_emotion_route(
    text: str,
    provider: str = "openai",
    model: Optional[str] = None,
    fallback_to_rule: bool = True
) -> str:
    """
    ä¸»è¦æ¥å£ï¼šä½¿ç”¨ LLM åˆ¤æ–·èªæ°£ä¸¦æ’å…¥æ¨™ç±¤
    
    Args:
        text: è¼¸å…¥æ–‡å­—
        provider: LLM æä¾›è€…ï¼ˆ"openai" æˆ– "anthropic"ï¼‰
        model: æ¨¡å‹åç¨±ï¼ˆå¯é¸ï¼Œä½¿ç”¨ç’°å¢ƒè®Šæ•¸æˆ–é è¨­å€¼ï¼‰
        fallback_to_rule: å¦‚æœ LLM å¤±æ•—ï¼Œæ˜¯å¦å›é€€åˆ°è¦å‰‡å¼åˆ¤æ–·
        
    Returns:
        åŠ ä¸Šèªæ°£æ¨™ç±¤çš„æ–‡å­—
    """
    # å˜—è©¦ä½¿ç”¨ LLM
    result = None
    
    if provider.lower() == "openai":
        model = model or OPENAI_MODEL  # ä½¿ç”¨ç’°å¢ƒè®Šæ•¸æˆ–æä¾›çš„æ¨¡å‹
        result = llm_emotion_route_openai(text, model)
    elif provider.lower() == "anthropic":
        model = model or "claude-3-haiku-20240307"
        result = llm_emotion_route_anthropic(text, model)
    else:
        print(f"âš ï¸  ä¸æ”¯æ´çš„ provider: {provider}ï¼Œä½¿ç”¨è¦å‰‡å¼åˆ¤æ–·")
    
    # å¦‚æœ LLM å¤±æ•—ä¸”å…è¨±å›é€€ï¼Œä½¿ç”¨è¦å‰‡å¼åˆ¤æ–·
    if not result and fallback_to_rule:
        from emotion_tag_engine import insert_emotion_tags
        result = insert_emotion_tags(text)
        print("ğŸ“Œ ä½¿ç”¨è¦å‰‡å¼èªæ°£åˆ¤æ–·")
    
    return result or text


# æ¸¬è©¦å‡½æ•¸
if __name__ == "__main__":
    test_texts = [
        "ä½ çŸ¥é“å—ï¼Ÿæˆ‘çœŸçš„å¥½æ„Ÿå‹•ã€‚",
        "å¤ªå¥½äº†ï¼æˆ‘å€‘æˆåŠŸäº†ï¼",
        "é€™æ˜¯å€‹ç§˜å¯†ï¼Œä¸è¦å‘Šè¨´åˆ¥äººã€‚",
        "æ°£æ­»æˆ‘äº†ï¼",
        "ä½ å¥½ï¼Œæˆ‘æ˜¯é»ƒè“‰ï¼",
    ]
    
    print("=" * 60)
    print("ğŸ§  LLM èªæ°£åˆ¤æ–·å™¨æ¸¬è©¦")
    print("=" * 60)
    print()
    
    for text in test_texts:
        print(f"åŸå§‹ï¼š{text}")
        
        # å˜—è©¦ä½¿ç”¨ OpenAIï¼ˆå¦‚æœå¯ç”¨ï¼‰
        result = llm_emotion_route(text, provider="openai", fallback_to_rule=True)
        print(f"çµæœï¼š{result}")
        print()

