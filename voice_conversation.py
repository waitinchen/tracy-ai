"""
ğŸ¤ æœ¬åœ°ç«¯é›™å‘èªéŸ³å°è©±æ¸¬è©¦ç³»çµ±

åŠŸèƒ½ï¼š
1. èªéŸ³è¼¸å…¥ï¼ˆSTT - Speech to Textï¼‰
2. æ–‡å­—è™•ç†ï¼ˆèªæ°£åˆ¤æ–·ï¼‰
3. èªéŸ³è¼¸å‡ºï¼ˆTTS - Text to Speechï¼‰
4. å¾ªç’°å°è©±
"""

import os
import sys
import time
from pathlib import Path
from dotenv import load_dotenv

# è¨­ç½® UTF-8 ç·¨ç¢¼
if sys.platform == 'win32':
    import io
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8', errors='replace')

load_dotenv()

# å°å…¥æ¨¡çµ„
from emotion_tag_engine import insert_emotion_tags
from modules.llm_emotion_router import llm_emotion_route
from eleven_tts import generate_speech


class VoiceConversation:
    """èªéŸ³å°è©±ç³»çµ±"""
    
    def __init__(self, use_llm=True, provider="openai"):
        self.use_llm = use_llm
        self.provider = provider
        self.conversation_history = []
        
    def speech_to_text(self, audio_file=None):
        """
        èªéŸ³è½‰æ–‡å­—ï¼ˆSTTï¼‰
        
        Args:
            audio_file: éŸ³è¨Šæª”æ¡ˆè·¯å¾‘ï¼ˆå¦‚æœç‚º Noneï¼Œå‰‡ä½¿ç”¨éº¥å…‹é¢¨éŒ„éŸ³ï¼‰
        
        Returns:
            è½‰æ›å¾Œçš„æ–‡å­—
        """
        # æ–¹æ³• 1: ä½¿ç”¨ OpenAI Whisper API
        if os.getenv("OPENAI_API_KEY"):
            try:
                import openai
                client = openai.OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
                
                if audio_file:
                    # å¾æª”æ¡ˆè®€å–
                    with open(audio_file, "rb") as f:
                        transcript = client.audio.transcriptions.create(
                            model="whisper-1",
                            file=f,
                            language="zh"
                        )
                else:
                    # å¾éº¥å…‹é¢¨éŒ„éŸ³ï¼ˆéœ€è¦å…ˆéŒ„è£½ï¼‰
                    print("âš ï¸  è«‹å…ˆéŒ„è£½éŸ³è¨Šæª”æ¡ˆï¼Œæˆ–ä½¿ç”¨ audio_file åƒæ•¸")
                    return None
                
                return transcript.text
            except ImportError:
                print("âš ï¸  æœªå®‰è£ openai å¥—ä»¶")
            except Exception as e:
                print(f"âŒ Whisper API éŒ¯èª¤: {str(e)}")
        
        # æ–¹æ³• 2: ä½¿ç”¨æœ¬åœ° Whisperï¼ˆå¦‚æœå®‰è£ï¼‰
        try:
            import whisper
            model = whisper.load_model("base")
            
            if audio_file:
                result = model.transcribe(audio_file, language="zh")
                return result["text"]
            else:
                print("âš ï¸  è«‹å…ˆéŒ„è£½éŸ³è¨Šæª”æ¡ˆ")
                return None
        except ImportError:
            print("âš ï¸  æœªå®‰è£ whisper å¥—ä»¶ï¼Œè«‹åŸ·è¡Œ: pip install openai-whisper")
        except Exception as e:
            print(f"âŒ Whisper éŒ¯èª¤: {str(e)}")
        
        # æ–¹æ³• 3: æ‰‹å‹•è¼¸å…¥ï¼ˆå‚™ç”¨ï¼‰
        print("âš ï¸  ä½¿ç”¨æ‰‹å‹•è¼¸å…¥æ¨¡å¼ï¼ˆå‚™ç”¨ï¼‰")
        return input("è«‹è¼¸å…¥æ–‡å­—: ").strip()
    
    def process_text(self, text):
        """
        è™•ç†æ–‡å­—ï¼ˆèªæ°£åˆ¤æ–·ï¼‰
        
        Args:
            text: è¼¸å…¥æ–‡å­—
        
        Returns:
            åŠ ä¸Šèªæ°£æ¨™ç±¤çš„æ–‡å­—
        """
        if self.use_llm and os.getenv("OPENAI_API_KEY"):
            try:
                tagged_text = llm_emotion_route(
                    text,
                    provider=self.provider,
                    fallback_to_rule=True
                )
                return tagged_text
            except Exception as e:
                print(f"âš ï¸  LLM åˆ¤æ–·å¤±æ•—ï¼Œä½¿ç”¨è¦å‰‡å¼: {str(e)}")
                return insert_emotion_tags(text)
        else:
            return insert_emotion_tags(text)
    
    def text_to_speech(self, text, output_file=None):
        """
        æ–‡å­—è½‰èªéŸ³ï¼ˆTTSï¼‰
        
        Args:
            text: è¦è½‰æ›çš„æ–‡å­—
            output_file: è¼¸å‡ºæª”æ¡ˆåç¨±
        
        Returns:
            éŸ³è¨Šæª”æ¡ˆè·¯å¾‘
        """
        if not output_file:
            timestamp = int(time.time())
            output_file = f"conversation_output_{timestamp}.mp3"
        
        success = generate_speech(text, filename=output_file)
        
        if success:
            return output_file
        else:
            return None
    
    def play_audio(self, audio_file):
        """
        æ’­æ”¾éŸ³è¨Šæª”æ¡ˆ
        
        Args:
            audio_file: éŸ³è¨Šæª”æ¡ˆè·¯å¾‘
        """
        try:
            # æ–¹æ³• 1: ä½¿ç”¨ playsound
            try:
                from playsound import playsound
                playsound(audio_file)
                return True
            except ImportError:
                pass
            
            # æ–¹æ³• 2: ä½¿ç”¨ pydub
            try:
                from pydub import AudioSegment
                from pydub.playback import play
                audio = AudioSegment.from_mp3(audio_file)
                play(audio)
                return True
            except ImportError:
                pass
            
            # æ–¹æ³• 3: Windows ç³»çµ±å‘½ä»¤
            if sys.platform == 'win32':
                os.startfile(audio_file)
                return True
            
            # æ–¹æ³• 4: æç¤ºæ‰‹å‹•æ’­æ”¾
            print(f"ğŸ’¡ è«‹æ‰‹å‹•æ’­æ”¾éŸ³è¨Šæª”æ¡ˆ: {audio_file}")
            return False
            
        except Exception as e:
            print(f"âŒ æ’­æ”¾éŒ¯èª¤: {str(e)}")
            print(f"ğŸ’¡ è«‹æ‰‹å‹•æ’­æ”¾: {audio_file}")
            return False
    
    def conversation_loop(self, input_mode="manual"):
        """
        å°è©±å¾ªç’°
        
        Args:
            input_mode: è¼¸å…¥æ¨¡å¼ ("manual" æˆ– "voice")
        """
        print("=" * 60)
        print("ğŸ¤ é»ƒè“‰èªéŸ³å°è©±ç³»çµ±")
        print("=" * 60)
        print("\nå°è©±æ¨¡å¼å·²å•Ÿå‹•")
        print("è¼¸å…¥ 'quit' æˆ– 'exit' çµæŸå°è©±\n")
        
        while True:
            try:
                # Step 1: èªéŸ³è¼¸å…¥æˆ–æ–‡å­—è¼¸å…¥
                if input_mode == "voice":
                    print("ğŸ¤ è«‹èªªè©±ï¼ˆéŒ„éŸ³ä¸­...ï¼‰")
                    user_input = self.speech_to_text()
                    if not user_input:
                        print("âš ï¸  ç„¡æ³•å–å¾—èªéŸ³è¼¸å…¥ï¼Œè«‹ä½¿ç”¨æ‰‹å‹•è¼¸å…¥æ¨¡å¼")
                        user_input = input("ğŸ“ è«‹è¼¸å…¥æ–‡å­—: ").strip()
                else:
                    user_input = input("ğŸ“ è«‹è¼¸å…¥æ–‡å­—: ").strip()
                
                if not user_input:
                    continue
                
                if user_input.lower() in ['quit', 'exit', 'é€€å‡º', 'çµæŸ']:
                    print("\nğŸ‘‹ å°è©±çµæŸï¼Œå†è¦‹ï¼")
                    break
                
                # è¨˜éŒ„å°è©±æ­·å²
                self.conversation_history.append({"role": "user", "text": user_input})
                print(f"\nğŸ‘¤ ä½ èªª: {user_input}")
                
                # Step 2: è™•ç†æ–‡å­—ï¼ˆèªæ°£åˆ¤æ–·ï¼‰
                print("ğŸ”„ è™•ç†ä¸­...")
                tagged_text = self.process_text(user_input)
                print(f"ğŸ·ï¸  æ¨™ç±¤å¾Œ: {tagged_text}")
                
                # Step 3: ç”¢ç”ŸèªéŸ³
                print("ğŸµ ç”¢ç”ŸèªéŸ³ä¸­...")
                audio_file = self.text_to_speech(tagged_text)
                
                if audio_file:
                    print(f"âœ… èªéŸ³å·²ç”¢ç”Ÿ: {audio_file}")
                    
                    # Step 4: æ’­æ”¾èªéŸ³
                    print("ğŸ”Š æ’­æ”¾èªéŸ³...")
                    self.play_audio(audio_file)
                    
                    # è¨˜éŒ„å°è©±æ­·å²
                    self.conversation_history.append({
                        "role": "assistant",
                        "text": tagged_text,
                        "audio": audio_file
                    })
                else:
                    print("âŒ èªéŸ³ç”¢ç”Ÿå¤±æ•—")
                
                print("\n" + "-" * 60 + "\n")
                
            except KeyboardInterrupt:
                print("\n\nğŸ‘‹ å°è©±ä¸­æ–·ï¼Œå†è¦‹ï¼")
                break
            except Exception as e:
                print(f"\nâŒ ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
                import traceback
                traceback.print_exc()
                print()


def main():
    """ä¸»å‡½æ•¸"""
    import argparse
    
    parser = argparse.ArgumentParser(description="é»ƒè“‰èªéŸ³å°è©±ç³»çµ±")
    parser.add_argument(
        "--mode",
        choices=["manual", "voice"],
        default="manual",
        help="è¼¸å…¥æ¨¡å¼: manual (æ‰‹å‹•è¼¸å…¥) æˆ– voice (èªéŸ³è¼¸å…¥)"
    )
    parser.add_argument(
        "--no-llm",
        action="store_true",
        help="ä¸ä½¿ç”¨ LLM èªæ°£åˆ¤æ–·ï¼Œä½¿ç”¨è¦å‰‡å¼åˆ¤æ–·"
    )
    parser.add_argument(
        "--provider",
        choices=["openai", "anthropic"],
        default="openai",
        help="LLM æä¾›è€…"
    )
    
    args = parser.parse_args()
    
    # å‰µå»ºå°è©±ç³»çµ±
    conversation = VoiceConversation(
        use_llm=not args.no_llm,
        provider=args.provider
    )
    
    # å•Ÿå‹•å°è©±å¾ªç’°
    conversation.conversation_loop(input_mode=args.mode)


if __name__ == "__main__":
    main()


