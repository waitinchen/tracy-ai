"""
ğŸ§ª æ¸¬è©¦å·¥å…·ï¼šç”¨æ–¼æ¸¬è©¦å’Œèª¿è©¦èªæ°£æ¨™ç±¤èˆ‡èªéŸ³ç”¢ç”Ÿ
"""

from emotion_tag_engine import insert_emotion_tags, AVAILABLE_EMOTION_TAGS
from eleven_tts import generate_speech, get_voice_info, list_available_voices


def test_emotion_tags():
    """æ¸¬è©¦èªæ°£æ¨™ç±¤æ’å…¥åŠŸèƒ½"""
    print("=" * 60)
    print("ğŸ§ª æ¸¬è©¦èªæ°£æ¨™ç±¤æ’å…¥åŠŸèƒ½")
    print("=" * 60)
    print()
    
    test_cases = [
        "ä½ å¥½ï¼Œæˆ‘æ˜¯é»ƒè“‰ï¼",
        "é€™æ˜¯å€‹ç§˜å¯†ï¼Œä¸è¦å‘Šè¨´åˆ¥äºº",
        "å—šå—šï¼Œæˆ‘å¥½é›£é",
        "æ°£æ­»æˆ‘äº†ï¼",
        "ä½ çŸ¥é“å—ï¼Ÿ",
        "ä»Šå¤©å¤©æ°£çœŸå¥½",
    ]
    
    for text in test_cases:
        tagged = insert_emotion_tags(text)
        print(f"åŸå§‹ï¼š{text}")
        print(f"æ¨™ç±¤ï¼š{tagged}")
        print()


def test_voice_info():
    """æ¸¬è©¦å–å¾—è²ç·šè³‡è¨Š"""
    print("=" * 60)
    print("ğŸ” æª¢æŸ¥è²ç·šè¨­å®š")
    print("=" * 60)
    print()
    
    voice_info = get_voice_info()
    if voice_info:
        print("âœ… è²ç·šè³‡è¨Šï¼š")
        print(f"  åç¨±ï¼š{voice_info.get('name', 'N/A')}")
        print(f"  Voice IDï¼š{voice_info.get('voice_id', 'N/A')}")
        print(f"  é¡åˆ¥ï¼š{voice_info.get('category', 'N/A')}")
    else:
        print("âŒ ç„¡æ³•å–å¾—è²ç·šè³‡è¨Šï¼Œè«‹æª¢æŸ¥ .env è¨­å®š")


def test_list_voices():
    """åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„è²ç·š"""
    print("=" * 60)
    print("ğŸ“‹ åˆ—å‡ºæ‰€æœ‰å¯ç”¨è²ç·š")
    print("=" * 60)
    print()
    
    voices = list_available_voices()
    if voices:
        print(f"æ‰¾åˆ° {len(voices)} å€‹è²ç·šï¼š\n")
        for i, voice in enumerate(voices, 1):
            print(f"{i}. {voice.get('name', 'N/A')}")
            print(f"   ID: {voice.get('voice_id', 'N/A')}")
            print(f"   é¡åˆ¥: {voice.get('category', 'N/A')}")
            print()
    else:
        print("âŒ ç„¡æ³•å–å¾—è²ç·šåˆ—è¡¨ï¼Œè«‹æª¢æŸ¥ API Key")


def test_single_speech(text: str = "ä½ å¥½ï¼Œæˆ‘æ˜¯é»ƒè“‰"):
    """æ¸¬è©¦å–®ä¸€èªéŸ³ç”¢ç”Ÿ"""
    print("=" * 60)
    print("ğŸ¤ æ¸¬è©¦èªéŸ³ç”¢ç”Ÿ")
    print("=" * 60)
    print()
    
    tagged_text = insert_emotion_tags(text)
    print(f"åŸå§‹æ–‡å­—ï¼š{text}")
    print(f"æ¨™ç±¤æ–‡å­—ï¼š{tagged_text}")
    print()
    
    filename = "test_output.mp3"
    success = generate_speech(tagged_text, filename=filename)
    
    if success:
        print(f"\nâœ… æ¸¬è©¦æˆåŠŸï¼æª”æ¡ˆï¼š{filename}")
    else:
        print("\nâŒ æ¸¬è©¦å¤±æ•—ï¼Œè«‹æª¢æŸ¥è¨­å®š")


if __name__ == "__main__":
    import sys
    
    if len(sys.argv) > 1:
        command = sys.argv[1]
        
        if command == "emotion":
            test_emotion_tags()
        elif command == "voice":
            test_voice_info()
        elif command == "list":
            test_list_voices()
        elif command == "speech":
            text = sys.argv[2] if len(sys.argv) > 2 else "ä½ å¥½ï¼Œæˆ‘æ˜¯é»ƒè“‰"
            test_single_speech(text)
        else:
            print("å¯ç”¨æŒ‡ä»¤ï¼š")
            print("  python test_tools.py emotion  - æ¸¬è©¦èªæ°£æ¨™ç±¤")
            print("  python test_tools.py voice    - æª¢æŸ¥è²ç·šè¨­å®š")
            print("  python test_tools.py list     - åˆ—å‡ºæ‰€æœ‰è²ç·š")
            print("  python test_tools.py speech [æ–‡å­—] - æ¸¬è©¦èªéŸ³ç”¢ç”Ÿ")
    else:
        # åŸ·è¡Œæ‰€æœ‰æ¸¬è©¦
        test_emotion_tags()
        print("\n")
        test_voice_info()
        print("\n")
        test_single_speech()


