"""
å¿«é€Ÿæ¸¬è©¦è…³æœ¬ï¼šé›™å‘èªéŸ³å°è©±
"""

import os
import sys
import time
from dotenv import load_dotenv

if sys.platform == 'win32':
    import io
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')

load_dotenv()

from emotion_tag_engine import insert_emotion_tags
from modules.llm_emotion_router import llm_emotion_route
from eleven_tts import generate_speech


def main():
    print("=" * 60)
    print("é»ƒè“‰èªéŸ³å°è©±ç³»çµ± - å¿«é€Ÿæ¸¬è©¦")
    print("=" * 60)
    print("\nè¼¸å…¥æ–‡å­—ï¼Œç³»çµ±æœƒè‡ªå‹•è™•ç†ä¸¦æ’­æ”¾èªéŸ³")
    print("è¼¸å…¥ 'quit' çµæŸ\n")
    
    count = 0
    
    while True:
        try:
            text = input("ğŸ“ ä½ èªª: ").strip()
            
            if not text:
                continue
            
            if text.lower() in ['quit', 'exit', 'é€€å‡º']:
                print("\nğŸ‘‹ å†è¦‹ï¼")
                break
            
            count += 1
            print(f"\n[å°è©± #{count}]")
            
            # èªæ°£åˆ¤æ–·
            if os.getenv("OPENAI_API_KEY"):
                try:
                    tagged = llm_emotion_route(text, provider="openai", fallback_to_rule=True)
                except:
                    tagged = insert_emotion_tags(text)
            else:
                tagged = insert_emotion_tags(text)
            
            print(f"ğŸ·ï¸  {tagged}")
            
            # ç”¢ç”ŸèªéŸ³
            audio_file = f"conv_{int(time.time())}.mp3"
            if generate_speech(tagged, filename=audio_file):
                print(f"âœ… {audio_file}")
                try:
                    os.startfile(audio_file)
                except:
                    print(f"ğŸ’¡ è«‹æ’­æ”¾: {audio_file}")
            
            print()
            
        except KeyboardInterrupt:
            print("\n\nğŸ‘‹ å†è¦‹ï¼")
            break
        except Exception as e:
            print(f"âŒ éŒ¯èª¤: {e}\n")


if __name__ == "__main__":
    main()


