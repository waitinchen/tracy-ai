"""
ğŸ¤ ç°¡åŒ–ç‰ˆèªéŸ³å°è©±æ¸¬è©¦ï¼ˆå¿«é€Ÿæ¸¬è©¦ç”¨ï¼‰

ä½¿ç”¨æ‰‹å‹•è¼¸å…¥æ¨¡æ“¬èªéŸ³å°è©±æµç¨‹
"""

import os
import sys
import time
from pathlib import Path
from dotenv import load_dotenv

# è¨­ç½® UTF-8 ç·¨ç¢¼
if sys.platform == 'win32':
    import io
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8', errors='replace')

load_dotenv()

from emotion_tag_engine import insert_emotion_tags
from modules.llm_emotion_router import llm_emotion_route
from eleven_tts import generate_speech


def play_audio_windows(audio_file):
    """Windows æ’­æ”¾éŸ³è¨Š"""
    try:
        os.startfile(audio_file)
        return True
    except Exception as e:
        print(f"æ’­æ”¾éŒ¯èª¤: {str(e)}")
        return False


def conversation_test():
    """å°è©±æ¸¬è©¦"""
    print("=" * 60)
    print("é»ƒè“‰èªéŸ³å°è©±ç³»çµ± - æ¸¬è©¦æ¨¡å¼")
    print("=" * 60)
    print("\né€™æ˜¯ä¸€å€‹ç°¡åŒ–çš„å°è©±æ¸¬è©¦")
    print("è¼¸å…¥æ–‡å­—ï¼Œç³»çµ±æœƒè‡ªå‹•åŠ ä¸Šèªæ°£æ¨™ç±¤ä¸¦ç”¢ç”ŸèªéŸ³")
    print("è¼¸å…¥ 'quit' çµæŸ\n")
    
    use_llm = bool(os.getenv("OPENAI_API_KEY"))
    if use_llm:
        print("âœ… LLM èªæ°£åˆ¤æ–·å·²å•Ÿç”¨ï¼ˆä½¿ç”¨ GPTï¼‰")
    else:
        print("âš ï¸  LLM èªæ°£åˆ¤æ–·æœªå•Ÿç”¨ï¼ˆä½¿ç”¨è¦å‰‡å¼åˆ¤æ–·ï¼‰")
    
    print("\n" + "-" * 60 + "\n")
    
    conversation_count = 0
    
    while True:
        try:
            # è¼¸å…¥æ–‡å­—
            user_input = input("ğŸ“ ä½ èªª: ").strip()
            
            if not user_input:
                continue
            
            if user_input.lower() in ['quit', 'exit', 'é€€å‡º', 'çµæŸ']:
                print("\nğŸ‘‹ å°è©±çµæŸï¼")
                break
            
            conversation_count += 1
            print(f"\n[å°è©± #{conversation_count}]")
            
            # è™•ç†æ–‡å­—ï¼ˆèªæ°£åˆ¤æ–·ï¼‰
            print("ğŸ”„ è™•ç†ä¸­...")
            if use_llm:
                try:
                    tagged_text = llm_emotion_route(
                        user_input,
                        provider="openai",
                        fallback_to_rule=True
                    )
                    print(f"ğŸ·ï¸  æ¨™ç±¤å¾Œ: {tagged_text}")
                except Exception as e:
                    print(f"âš ï¸  LLM å¤±æ•—ï¼Œä½¿ç”¨è¦å‰‡å¼: {str(e)}")
                    tagged_text = insert_emotion_tags(user_input)
                    print(f"ğŸ·ï¸  æ¨™ç±¤å¾Œ: {tagged_text}")
            else:
                tagged_text = insert_emotion_tags(user_input)
                print(f"ğŸ·ï¸  æ¨™ç±¤å¾Œ: {tagged_text}")
            
            # ç”¢ç”ŸèªéŸ³
            print("ğŸµ ç”¢ç”ŸèªéŸ³ä¸­...")
            timestamp = int(time.time())
            audio_file = f"conversation_{timestamp}.mp3"
            
            success = generate_speech(tagged_text, filename=audio_file)
            
            if success:
                print(f"âœ… èªéŸ³å·²ç”¢ç”Ÿ: {audio_file}")
                
                # æ’­æ”¾èªéŸ³
                print("ğŸ”Š æ’­æ”¾èªéŸ³...")
                if play_audio_windows(audio_file):
                    print("âœ… æ’­æ”¾ä¸­...")
                else:
                    print(f"ğŸ’¡ è«‹æ‰‹å‹•æ’­æ”¾: {audio_file}")
            else:
                print("âŒ èªéŸ³ç”¢ç”Ÿå¤±æ•—")
            
            print("\n" + "-" * 60 + "\n")
            
        except KeyboardInterrupt:
            print("\n\nğŸ‘‹ å°è©±ä¸­æ–·ï¼")
            break
        except Exception as e:
            print(f"\nâŒ éŒ¯èª¤: {str(e)}")
            import traceback
            traceback.print_exc()
            print()


if __name__ == "__main__":
    conversation_test()


