import React, { useCallback, useEffect, useRef, useState } from "react";

const SERVICE_API_KEY =
  import.meta.env.VITE_SERVICE_API_KEY || "RIUvXLm99TG_jOyN6gP1vTYE1fdmXyMxL5tLDzMwFiA";

type WhisperMessage =
  | { type: "ready" }
  | { type: "final"; text: string }
  | { type: "error"; message: string };

type MicRecorderProps = {
  onVoiceTagsChange?: (tags: string[]) => void;
  onSpeakingChange?: (speaking: boolean) => void;
};

type TranscriptEntry = {
  id: string;
  type: WhisperMessage["type"];
  text: string;
};

const MicRecorder: React.FC<MicRecorderProps> = ({ onVoiceTagsChange, onSpeakingChange }) => {
  const [isRecording, setIsRecording] = useState(false);
  const [status, setStatus] = useState<string>("å°šæœªé€£ç·š");
  const [transcripts, setTranscripts] = useState<TranscriptEntry[]>([]);
  const [isGeneratingVoice, setIsGeneratingVoice] = useState(false);
  const [voiceAudioSrc, setVoiceAudioSrc] = useState<string | null>(null);
  const [voiceTags, setVoiceTags] = useState<string[]>([]);
  const [voiceMessage, setVoiceMessage] = useState<string>("");
  const [isVoicePlaying, setIsVoicePlaying] = useState(false);

  const wsRef = useRef<WebSocket | null>(null);
  const recorderRef = useRef<MediaRecorder | null>(null);
  const streamRef = useRef<MediaStream | null>(null);

  useEffect(() => {
    onVoiceTagsChange?.(voiceTags);
  }, [voiceTags, onVoiceTagsChange]);

  useEffect(() => {
    onSpeakingChange?.(isVoicePlaying || isRecording || isGeneratingVoice);
  }, [isVoicePlaying, isRecording, isGeneratingVoice, onSpeakingChange]);

  const appendTranscript = useCallback((entry: TranscriptEntry) => {
    setTranscripts((prev) => [...prev, entry]);
  }, []);

  const triggerTTS = useCallback(async (text: string) => {
    if (!text.trim()) return;

    setIsGeneratingVoice(true);
    setVoiceMessage("æ­£åœ¨ç”ŸæˆèªéŸ³...");
    setVoiceTags([]);

    try {
      const response = await fetch("/api/voice/huangrong", {
        method: "POST",
        headers: {
          "Content-Type": "application/json",
          "Service-Api-Key": SERVICE_API_KEY,
        },
        body: JSON.stringify({ text, emotion_auto: true }),
      });

      if (!response.ok) {
        const errorBody = await response.text();
        throw new Error(`èªéŸ³ API å¤±æ•—ï¼š${response.status} ${errorBody}`);
      }

      const data = await response.json();
      setVoiceAudioSrc(data.audio_url || null);
      setVoiceTags(data.voice_tags || []);
      setVoiceMessage(data.message || "èªéŸ³å·²ç”¢ç”Ÿ");
      setIsVoicePlaying(false);
    } catch (error) {
      console.error("ç”¢ç”ŸèªéŸ³å¤±æ•—", error);
      setVoiceAudioSrc(null);
      setVoiceMessage(error instanceof Error ? error.message : "èªéŸ³ç”¢ç”Ÿå¤±æ•—");
      setVoiceTags([]);
    } finally {
      setIsGeneratingVoice(false);
    }
  }, []);

  const stopAll = useCallback(() => {
    recorderRef.current?.stop();
    recorderRef.current = null;

    streamRef.current?.getTracks().forEach((track) => track.stop());
    streamRef.current = null;

    wsRef.current?.close();
    wsRef.current = null;

    setIsRecording(false);
    setStatus("å·²åœæ­¢éŒ„éŸ³");
    setIsVoicePlaying(false);
  }, []);

  const handleWebSocketMessage = useCallback(
    (event: MessageEvent) => {
      let data: WhisperMessage;
      try {
        data = JSON.parse(event.data);
      } catch (error) {
        console.error("ç„¡æ³•è§£æ Whisper è¨Šæ¯", error);
        return;
      }

      if (data.type === "ready") {
        setStatus("Whisper é€£ç·šæˆåŠŸï¼Œé–‹å§‹éŒ„éŸ³");
        appendTranscript({ id: crypto.randomUUID(), type: "ready", text: "Whisper æœå‹™å·²å°±ç·’" });
        return;
      }

      if (data.type === "final") {
        appendTranscript({ id: crypto.randomUUID(), type: "final", text: data.text });
        triggerTTS(data.text);
        return;
      }

      if (data.type === "error") {
        appendTranscript({ id: crypto.randomUUID(), type: "error", text: data.message });
        setStatus(`Whisper ç™¼ç”ŸéŒ¯èª¤: ${data.message}`);
        stopAll();
      }
    },
    [appendTranscript, stopAll, triggerTTS]
  );

  const startRecording = useCallback(async () => {
    if (isRecording) {
      return;
    }

    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      streamRef.current = stream;

      const protocol = window.location.protocol === "https:" ? "wss" : "ws";
      const params = new URLSearchParams({ service_api_key: SERVICE_API_KEY });
      const wsUrl = `${protocol}://${window.location.host}/api/whisper?${params.toString()}`;
      const ws = new WebSocket(wsUrl);
      wsRef.current = ws;

      ws.onopen = () => {
        setStatus("å·²é€£ç·š Whisperï¼Œæº–å‚™éŒ„éŸ³...");
        const recorder = new MediaRecorder(stream, { mimeType: "audio/webm" });
        recorderRef.current = recorder;

        recorder.addEventListener("dataavailable", async (event) => {
          if (event.data.size === 0 || ws.readyState !== WebSocket.OPEN) return;

          try {
            const buffer = await event.data.arrayBuffer();
            ws.send(buffer);
          } catch (error) {
            console.error("å‚³é€éŸ³è¨Šç‰‡æ®µå¤±æ•—", error);
          }
        });

        recorder.start(1000); // æ¯ç§’ç”¢å‡ºä¸€å€‹ chunk
        setIsRecording(true);
        setStatus("éŒ„éŸ³ä¸­... é»æ“Šåœæ­¢ä»¥çµæŸ");
      };

      ws.onerror = (event) => {
        console.error("Whisper WebSocket éŒ¯èª¤", event);
        setStatus("Whisper WebSocket éŒ¯èª¤");
        stopAll();
      };

      ws.onmessage = handleWebSocketMessage;
      ws.onclose = () => {
        setStatus("Whisper é€£ç·šé—œé–‰");
        stopAll();
      };
    } catch (error) {
      console.error("å–å¾—éº¥å…‹é¢¨æ¬Šé™å¤±æ•—", error);
      setStatus("å–å¾—éº¥å…‹é¢¨æ¬Šé™å¤±æ•—ï¼Œè«‹å…è¨±å­˜å–");
    }
  }, [handleWebSocketMessage, isRecording, stopAll]);

  const stopRecording = useCallback(() => {
    stopAll();
  }, [stopAll]);

  useEffect(() => {
    return () => {
      stopAll();
    };
  }, [stopAll]);

  return (
    <div className="mic-recorder">
      <div className="controls">
        <button onClick={startRecording} disabled={isRecording}>
          ğŸ™ï¸ é–‹å§‹éŒ„éŸ³
        </button>
        <button onClick={stopRecording} disabled={!isRecording}>
          â¹ åœæ­¢
        </button>
      </div>
      <p className="status">{status}</p>

      <div className="transcripts">
        {transcripts.map((entry) => (
          <div key={entry.id} className={`transcript transcript-${entry.type}`}>
            <span className="transcript-label">[{entry.type}]</span>
            <span className="transcript-text">{entry.text}</span>
          </div>
        ))}
      </div>

      <div className="voice-output">
        <h3>å°è»ŸèªéŸ³å›æ‡‰</h3>
        {isGeneratingVoice && <p className="voice-status">ğŸ”„ {voiceMessage || "èªéŸ³ç”Ÿæˆä¸­..."}</p>}
        {!isGeneratingVoice && voiceMessage && <p className="voice-status">âœ… {voiceMessage}</p>}
        {voiceTags.length > 0 && (
          <p className="voice-tags">
            èªæ°£æ¨™ç±¤ï¼š{voiceTags.map((tag) => (
              <span key={tag} className="voice-tag">{tag}</span>
            ))}
          </p>
        )}
        {voiceAudioSrc && (
          <audio
            key={voiceAudioSrc}
            controls
            autoPlay
            src={voiceAudioSrc}
            className="voice-audio"
            onPlay={() => setIsVoicePlaying(true)}
            onPause={() => setIsVoicePlaying(false)}
            onEnded={() => setIsVoicePlaying(false)}
          />
        )}
      </div>
    </div>
  );
};

export default MicRecorder;

