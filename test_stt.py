"""
ğŸ™ï¸ èªéŸ³è¼¸å…¥æ¸¬è©¦ï¼ˆä½¿ç”¨ OpenAI Whisper APIï¼‰

éœ€è¦å…ˆéŒ„è£½éŸ³è¨Šæª”æ¡ˆï¼Œç„¶å¾Œè½‰æ›ç‚ºæ–‡å­—
"""

import os
import sys
from pathlib import Path
from dotenv import load_dotenv

load_dotenv()

def transcribe_audio(audio_file):
    """
    ä½¿ç”¨ OpenAI Whisper API è½‰æ›èªéŸ³ç‚ºæ–‡å­—
    
    Args:
        audio_file: éŸ³è¨Šæª”æ¡ˆè·¯å¾‘
    
    Returns:
        è½‰æ›å¾Œçš„æ–‡å­—
    """
    if not os.path.exists(audio_file):
        print(f"âŒ æª”æ¡ˆä¸å­˜åœ¨: {audio_file}")
        return None
    
    if not os.getenv("OPENAI_API_KEY"):
        print("âŒ æœªè¨­å®š OPENAI_API_KEY")
        return None
    
    try:
        import openai
        client = openai.OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
        
        print(f"ğŸ”„ æ­£åœ¨è½‰æ›èªéŸ³: {audio_file}")
        
        with open(audio_file, "rb") as f:
            transcript = client.audio.transcriptions.create(
                model="whisper-1",
                file=f,
                language="zh"
            )
        
        text = transcript.text
        print(f"âœ… è½‰æ›å®Œæˆ: {text}")
        return text
        
    except ImportError:
        print("âŒ æœªå®‰è£ openai å¥—ä»¶ï¼Œè«‹åŸ·è¡Œ: pip install openai")
        return None
    except Exception as e:
        print(f"âŒ è½‰æ›å¤±æ•—: {str(e)}")
        return None


def record_audio_windows():
    """
    Windows éŒ„éŸ³æç¤º
    
    Returns:
        éŒ„è£½çš„æª”æ¡ˆè·¯å¾‘
    """
    print("=" * 60)
    print("ğŸ™ï¸  èªéŸ³éŒ„è£½æç¤º")
    print("=" * 60)
    print("\nè«‹ä½¿ç”¨ä»¥ä¸‹æ–¹å¼éŒ„è£½èªéŸ³ï¼š")
    print("1. ä½¿ç”¨ Windows èªéŸ³éŒ„éŸ³æ©Ÿ")
    print("2. ä½¿ç”¨ Audacity")
    print("3. ä½¿ç”¨å…¶ä»–éŒ„éŸ³è»Ÿé«”")
    print("\néŒ„è£½å®Œæˆå¾Œï¼Œè«‹è¼¸å…¥æª”æ¡ˆè·¯å¾‘")
    print("æ”¯æ´æ ¼å¼: .mp3, .wav, .m4a, .webm\n")
    
    audio_file = input("è«‹è¼¸å…¥éŸ³è¨Šæª”æ¡ˆè·¯å¾‘: ").strip().strip('"')
    
    if os.path.exists(audio_file):
        return audio_file
    else:
        print(f"âŒ æª”æ¡ˆä¸å­˜åœ¨: {audio_file}")
        return None


def main():
    """ä¸»å‡½æ•¸"""
    import argparse
    
    parser = argparse.ArgumentParser(description="èªéŸ³è½‰æ–‡å­—æ¸¬è©¦")
    parser.add_argument(
        "audio_file",
        nargs="?",
        help="éŸ³è¨Šæª”æ¡ˆè·¯å¾‘ï¼ˆå¦‚æœæœªæä¾›ï¼Œæœƒæç¤ºéŒ„éŸ³ï¼‰"
    )
    
    args = parser.parse_args()
    
    if args.audio_file:
        audio_file = args.audio_file
    else:
        audio_file = record_audio_windows()
    
    if audio_file:
        text = transcribe_audio(audio_file)
        if text:
            print(f"\nğŸ“ è½‰æ›çµæœ: {text}")
            
            # å¯ä»¥é¸æ“‡ç¹¼çºŒè™•ç†
            continue_process = input("\næ˜¯å¦ç¹¼çºŒè™•ç†ï¼ˆåŠ ä¸Šèªæ°£æ¨™ç±¤ä¸¦ç”¢ç”ŸèªéŸ³ï¼‰? (y/n): ").strip().lower()
            if continue_process == 'y':
                from modules.llm_emotion_router import llm_emotion_route
                from eleven_tts import generate_speech
                
                tagged_text = llm_emotion_route(text, provider="openai", fallback_to_rule=True)
                print(f"ğŸ·ï¸  æ¨™ç±¤å¾Œ: {tagged_text}")
                
                output_file = "stt_output.mp3"
                if generate_speech(tagged_text, filename=output_file):
                    print(f"âœ… èªéŸ³å·²ç”¢ç”Ÿ: {output_file}")
                    import os
                    os.startfile(output_file)


if __name__ == "__main__":
    main()


